{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "narrow-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Reshape, Add, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import functools\n",
    "import tensorflow.keras.backend as K\n",
    "from scipy.sparse import dok_matrix\n",
    "import random\n",
    "\n",
    "\n",
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-crime",
   "metadata": {},
   "source": [
    "# Data Sequence Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gorgeous-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from spektral.utils import normalized_adjacency\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import gridfs\n",
    "import functools\n",
    "\n",
    "\n",
    "def get_target(users, graph, cos, user_id):\n",
    "    target = dict()\n",
    "    set_users = set(users)\n",
    "    for u in users:\n",
    "        for d in graph.neighbors(u):\n",
    "            if d in set_users:\n",
    "                target[(u, d)] = graph.edges[(u, d)]['weight']\n",
    "    del set_users\n",
    "\n",
    "    indices = np.asarray(list(target.keys()))\n",
    "    v_true = np.asarray([v for v in target.values()])\n",
    "    sim = np.asarray([cos[user_id[link[0]], user_id[link[1]]] for link in target.keys()])\n",
    "    mean = np.mean(sim)\n",
    "    std = np.std(sim)\n",
    "    dist = 1 - (sim - (mean - 2 * std)) / (4 * std)\n",
    "    full_dist = 1 - (cos - (mean - 2 * std)) / (4 * std)\n",
    "    return indices, v_true, np.clip(dist, 0.1, 0.9), np.clip(full_dist, 0.1, 0.9)\n",
    "\n",
    "    \n",
    "class TwitterDataset(Sequence):\n",
    "    \n",
    "    def __init__(self, user_id, users,\n",
    "                 replies, mentions, retweets, full_graph,\n",
    "                 cos, max_tweets, batch_size, date_limit, db,\n",
    "                 neg_sample=1):\n",
    "        self.users_id = user_id\n",
    "        self.id_users = [0] * len(self.users_id)\n",
    "        for k, v in user_id.items():\n",
    "            self.id_users[v] = k \n",
    "        self.graph_replies = replies\n",
    "        self.graph_mentions = mentions\n",
    "        self.graph_retweets = retweets\n",
    "        self.graph_full = full_graph\n",
    "        self.center_users = [u for u in self.graph_full.nodes if self.graph_full.nodes[u]['central']]\n",
    "        self.center_users.sort()\n",
    "        self.user_pairs, self.y_true, \\\n",
    "        self.y_dist, self.distance = get_target(users, self.graph_full, cos, user_id)\n",
    "        self.idx_random = list(range(len(self.user_pairs)))\n",
    "        random.shuffle(self.idx_random)\n",
    "        self.max_tweets = max_tweets\n",
    "        self.batch_size = batch_size\n",
    "        #empty tweet representation\n",
    "        bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "        self.empty_tweet =  bert_model(**tokenizer('', return_tensors='tf'))['pooler_output'].numpy()\n",
    "        del bert_model\n",
    "        del tokenizer\n",
    "        self.date_limit = date_limit\n",
    "        self.gridfs = gridfs.GridFS(db, collection='fsProcessedTweets')\n",
    "        self._init_tweet_cache()\n",
    "        self.neg_sample_batch = neg_sample + 1\n",
    "        pass\n",
    "        \n",
    "    def _init_tweet_cache(self):\n",
    "        if not os.path.exists('training_tweets.npy'):\n",
    "            self.tweets = np.zeros((len(self.id_users), self.max_tweets, 768), dtype=np.float32)\n",
    "            for i, t in tqdm(enumerate(self.id_users), total=len(self.id_users)):\n",
    "                self.tweets[i, ...] = self._get_tweets_bert_base(t)\n",
    "            np.save('training_tweets.npy', self.tweets)\n",
    "            return\n",
    "        self.tweets = np.load('training_tweets.npy')\n",
    "        self.tweets = np.mean(self.tweets, axis=1)\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.neg_sample_batch * math.ceil(len(self.idx_random) / self.batch_size)\n",
    "    \n",
    "    def _get_graph_for_node(self, node):\n",
    "        user = node#self.user_id[node]\n",
    "        node_map = {user: 0}\n",
    "        #Maps all the 1-level node to create the matrix\n",
    "        for neighbor in self.graph_replies.neighbors(node):\n",
    "            if neighbor not in node_map:\n",
    "                node_map[neighbor] = len(node_map)\n",
    "        #Creates the 3 matrixes\n",
    "        replies = np.eye(len(node_map))\n",
    "        #creates the Ã‚ matrix for the key node \n",
    "        for node, node_id in node_map.items():\n",
    "            for neighbor in self.graph_replies.neighbors(node):\n",
    "                if neighbor in node_map:\n",
    "                    replies[node_id, node_map[neighbor]] = 1\n",
    "                    \n",
    "        replies = normalized_adjacency(replies)\n",
    "        #Create the embedding vector\n",
    "        embeddings = np.zeros((len(node_map)))\n",
    "        for k, v in node_map.items():\n",
    "            #Convert the tweeter user id to the id acording to the nn\n",
    "            embeddings[v] = self.users_id[k] \n",
    "        return embeddings, replies\n",
    "\n",
    "    def _get_tweets_bert(self, node):\n",
    "        return self.tweets[int(node), ...]\n",
    "    \n",
    "    def _get_tweets_bert_base(self, node):\n",
    "        user_id = node##\n",
    "        query = {'userId': int(user_id)}\n",
    "        if self.date_limit is not None:\n",
    "            query['created'] = {'$lte': self.date_limit}\n",
    "        cursor = (\n",
    "            self.gridfs.\n",
    "            find(query).\n",
    "            sort([('created', pymongo.DESCENDING)]).\n",
    "            limit(self.max_tweets)\n",
    "        )\n",
    "        result = np.empty((self.max_tweets, 768))\n",
    "        i = 0\n",
    "        for file in cursor:\n",
    "            result[i, :] = np.load(file)['pooler_output']\n",
    "            i += 1\n",
    "        while i < self.max_tweets:\n",
    "            result[i, :] = self.empty_tweet\n",
    "            i += 1\n",
    "        return result\n",
    "    \n",
    "    def _get_instance(self, node):\n",
    "        embeddings, replies = self._get_graph_for_node(node)\n",
    "        bert_emb = np.empty((embeddings.shape[0], 768))\n",
    "        for i, node in enumerate(embeddings):\n",
    "            bert_emb[i, ...] = self._get_tweets_bert(node)\n",
    "        return embeddings, replies, bert_emb\n",
    "    \n",
    "    def _to_batch(self, instances, max_users):\n",
    "        user_i = np.zeros((batch_size, max_users))\n",
    "        user_replies = np.zeros((batch_size, max_users, max_users))\n",
    "        user_bert = np.zeros((batch_size, max_users, 768))\n",
    "        for i, (embeddings, replies, bert_emb) in enumerate(instances):\n",
    "            user_i[i, :embeddings.shape[0]] = embeddings\n",
    "            user_replies[i, :replies.shape[0], :replies.shape[1]] = replies\n",
    "            user_bert[i, :bert_emb.shape[0], ...] = bert_emb\n",
    "        return [user_i, user_replies, user_bert]\n",
    "    \n",
    "    def gen_neg_sample(self):\n",
    "        users = random.sample(self.center_users, self.batch_size)\n",
    "        targets = random.sample(self.center_users, self.batch_size)\n",
    "        user_instances = [self._get_instance(u) for u in users]\n",
    "        target_instances = [self._get_instance(u) for u in targets]\n",
    "        max_user = max([len(instance[0]) for instance in user_instances]) \n",
    "        max_target = max([len(instance[0]) for instance in target_instances])\n",
    "        y = np.empty((self.batch_size, 2))\n",
    "        #y[:, :] = 0.5\n",
    "        y[:, 0] = 0.5\n",
    "        for i, (u, t) in enumerate(zip(users, targets)):\n",
    "            y[i, 1] = 1 - self.distance[self.users_id[u], self.users_id[t]]\n",
    "        return self._to_batch(user_instances, max_user) + self._to_batch(target_instances, max_target), y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if (idx % self.neg_sample_batch) != 0:\n",
    "            return self.gen_neg_sample()\n",
    "        idx = idx // self.neg_sample_batch\n",
    "        ids = self.idx_random[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        user_instances = [self._get_instance(self.user_pairs[idx][0]) for idx in ids]\n",
    "        target_instances = [self._get_instance(self.user_pairs[idx][1]) for idx in ids]\n",
    "        max_user = max([len(instance[0]) for instance in user_instances]) \n",
    "        max_target = max([len(instance[0]) for instance in target_instances])\n",
    "        current_batch_size = len(ids)\n",
    "        y = np.empty((current_batch_size, 2))\n",
    "        y[:, 0] = self.y_true[ids]\n",
    "        y[:, 1] = self.y_dist[ids]\n",
    "        return self._to_batch(user_instances, max_user) + self._to_batch(target_instances, max_target), y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.idx_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confident-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweets = 15\n",
    "batch_size = 20\n",
    "with open('train_ds.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "user_id = dataset.users_id\n",
    "\n",
    "dataset.batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "domestic-drinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.42597759],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.6734482 ],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.10000002],\n",
       "       [0.5       , 0.74929076],\n",
       "       [0.5       , 0.47525048],\n",
       "       [0.5       , 0.10000002]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 62)\n",
      "(20, 62, 62)\n",
      "(20, 62, 768)\n",
      "(20, 28)\n",
      "(20, 28, 28)\n",
      "(20, 28, 768)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset[0][0]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-pottery",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arbitrary-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Input, Embedding, Concatenate, \\\n",
    "                TimeDistributed, Lambda, Dot, Attention, GlobalMaxPool1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.layers.convolutional import GCNConv\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    #recibe indices con forma 1xvaloresx3 (indices + valor)\n",
    "    #trasnforma los indices a valoresx2 y los valores valoresx1\n",
    "    v_true, dist = y_true[:, 0], y_true[:, 1]\n",
    "    return K.mean(dist * K.square(y_pred - K.log(2 * v_true) / K.log(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "awful-rates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function modal_dot at 0x0000023740106700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function modal_dot at 0x0000023740106700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_list (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_tweets_bert (InputLayer)   [(None, None, 768)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target_list (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target_tweets_bert (InputLayer) [(None, None, 768)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embeddings (Embedding)     (None, None, 64)     412800      user_list[0][0]                  \n",
      "                                                                 target_list[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "user_bert_dense (Dense)         (None, None, 64)     49216       user_tweets_bert[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "target_bert_dense (Dense)       (None, None, 64)     49216       target_tweets_bert[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "user_emb_plus_bert (Concatenate (None, None, 128)    0           user_embeddings[0][0]            \n",
      "                                                                 user_bert_dense[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "replies_user (InputLayer)       [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target_emb_plus_bert (Concatena (None, None, 128)    0           user_embeddings[1][0]            \n",
      "                                                                 target_bert_dense[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "replies_target (InputLayer)     [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_replies_0 (GCNConv)         (None, None, 32)     4128        user_emb_plus_bert[0][0]         \n",
      "                                                                 replies_user[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gcn_t_replies_0 (GCNConv)       (None, None, 32)     4128        target_emb_plus_bert[0][0]       \n",
      "                                                                 replies_target[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user_row (Lambda)               (None, 32)           0           gcn_replies_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "target_row (Lambda)             (None, 32)           0           gcn_t_replies_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "graph_reps_concat (Concatenate) (None, 64)           0           user_row[0][0]                   \n",
      "                                                                 target_row[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "user_wide (Lambda)              (None, 64)           0           user_embeddings[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "target_wide (Lambda)            (None, 64)           0           user_embeddings[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        graph_reps_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reps_concat (Concatenate)       (None, 128)          0           user_wide[0][0]                  \n",
      "                                                                 target_wide[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            129         reps_concat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 1)]          0           dense_2[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 521,730\n",
      "Trainable params: 521,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_size = 64\n",
    "kernels = 32\n",
    "deep = 1\n",
    "\n",
    "embedded = Embedding(len(user_id), emb_size, name='user_embeddings')\n",
    "\n",
    "user_i = Input(shape=(None,), name='user_list', dtype=tf.int32)\n",
    "emb_user = embedded(user_i)\n",
    "\n",
    "target_i = Input(shape=(None,), name='target_list', dtype=tf.int32)\n",
    "emb_target = embedded(target_i)\n",
    "\n",
    "replies_user_i = Input(shape=(None, None), name='replies_user', dtype=tf.float32)\n",
    "\n",
    "replies_target_i = Input(shape=(None, None), name='replies_target', dtype=tf.float32)\n",
    "\n",
    "user_tweets_bert = Input(shape=(None, 768), name='user_tweets_bert')\n",
    "target_tweets_bert = Input(shape=(None, 768), name='target_tweets_bert')\n",
    "\n",
    "user_bert = Dense(emb_size, name='user_bert_dense')(user_tweets_bert)\n",
    "target_bert = Dense(emb_size, name='target_bert_dense')(target_tweets_bert)\n",
    "\n",
    "user_emb = Concatenate(name='user_emb_plus_bert', axis=-1)([emb_user, user_bert])\n",
    "target_emb = Concatenate(name='target_emb_plus_bert', axis=-1)([emb_target, target_bert])\n",
    "\n",
    "emb_rep, emb_men, emb_rt = user_emb, user_emb, user_emb\n",
    "emb_t_rep, emb_t_men, emb_t_rt = target_emb, target_emb, target_emb\n",
    "for i in range(deep):\n",
    "    emb_rep = GCNConv(kernels, name='gcn_replies_{}'.format(i))([emb_rep, replies_user_i])\n",
    "    \n",
    "    emb_t_rep = GCNConv(kernels, name='gcn_t_replies_{}'.format(i))([emb_t_rep, replies_target_i])\n",
    "    \n",
    "mat = emb_rep\n",
    "mat = Lambda(lambda x: x[:, 0, :], name='user_row')(mat)\n",
    "\n",
    "mat_t = emb_t_rep\n",
    "mat_t = Lambda(lambda x: x[:, 0, :], name='target_row')(mat_t)\n",
    "#Wide \n",
    "user_wide = Lambda(lambda x: x[:, 0, :], name='user_wide')(emb_user) \n",
    "target_wide = Lambda(lambda x: x[:, 0, :], name='target_wide')(emb_target) \n",
    "wide = Concatenate(name='reps_concat')([user_wide, target_wide])\n",
    "wide = Dense(1)(wide)\n",
    "#Falta unir con bert\n",
    "mat = Concatenate(name='graph_reps_concat')([mat, mat_t])\n",
    "mat = Dense(kernels)(mat)#, [0, 2, 1]\n",
    "mat = Dense(1)(mat)\n",
    "mat = mat + wide\n",
    "model = Model([user_i, replies_user_i, user_tweets_bert,\n",
    "              target_i, replies_target_i, target_tweets_bert], mat)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "different-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:AutoGraph could not transform <function loss at 0x00000237177479D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function loss at 0x00000237177479D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "31162/31162 [==============================] - 957s 31ms/step - loss: 0.61350s - loss: 0.\n",
      "Epoch 2/4\n",
      "31162/31162 [==============================] - 948s 30ms/step - loss: 0.5832\n",
      "Epoch 3/4\n",
      "31162/31162 [==============================] - 879s 28ms/step - loss: 0.5801\n",
      "Epoch 4/4\n",
      "31162/31162 [==============================] - 816s 26ms/step - loss: 0.5787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2373f3d36a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import os\n",
    "if not os.path.exists('connected-neg-replies'):\n",
    "    os.makedirs('connected-neg-replies')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 2:\n",
    "        return lr\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "model.fit(dataset, epochs=4, callbacks=[ModelCheckpoint(filepath='connected-neg-replies/{epoch:02d}-weights-neg-{loss:.5f}.hdf5',\n",
    "                                                        monitor='loss',\n",
    "                                                        save_best_only=False),\n",
    "                                         LearningRateScheduler(scheduler)], workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "inappropriate-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('connected-neg-replies/model_rec-neg.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
