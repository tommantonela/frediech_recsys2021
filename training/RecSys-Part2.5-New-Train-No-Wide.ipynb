{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Reshape, Add, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import functools\n",
    "import tensorflow.keras.backend as K\n",
    "from scipy.sparse import dok_matrix\n",
    "import random\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sequence Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.utils import normalized_adjacency\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import gridfs\n",
    "import functools\n",
    "\n",
    "\n",
    "def get_target(users, graph, cos, user_id):\n",
    "    target = dict()\n",
    "    set_users = set(users)\n",
    "    for u in users:\n",
    "        for d in graph.neighbors(u):\n",
    "            if d in set_users:\n",
    "                target[(u, d)] = graph.edges[(u, d)]['weight']\n",
    "    del set_users\n",
    "\n",
    "    indices = np.asarray(list(target.keys()))\n",
    "    v_true = np.asarray([v for v in target.values()])\n",
    "    sim = np.asarray([cos[user_id[link[0]], user_id[link[1]]] for link in target.keys()])\n",
    "    mean = np.mean(sim)\n",
    "    std = np.std(sim)\n",
    "    dist = 1 - (sim - (mean - 2 * std)) / (4 * std)\n",
    "    full_dist = 1 - (cos - (mean - 2 * std)) / (4 * std)\n",
    "    return indices, v_true, np.clip(dist, 0.1, 0.9), np.clip(full_dist, 0.1, 0.9)\n",
    "\n",
    "    \n",
    "class TwitterDataset(Sequence):\n",
    "    \n",
    "    def __init__(self, user_id, users,\n",
    "                 replies, mentions, retweets, full_graph,\n",
    "                 cos, max_tweets, batch_size, date_limit, db):\n",
    "        self.users_id = user_id\n",
    "        self.id_users = [0] * len(self.users_id)\n",
    "        for k, v in user_id.items():\n",
    "            self.id_users[v] = k \n",
    "        self.graph_replies = replies\n",
    "        self.graph_mentions = mentions\n",
    "        self.graph_retweets = retweets\n",
    "        self.graph_full = full_graph\n",
    "        self.center_users = [u for u in self.graph_full.nodes if self.graph_full.nodes[u]['central']]\n",
    "        self.center_users.sort()\n",
    "        self.user_pairs, self.y_true, \\\n",
    "        self.y_dist, self.distance = get_target(users, self.graph_full, cos, user_id)\n",
    "        self.idx_random = list(range(len(self.user_pairs)))\n",
    "        random.shuffle(self.idx_random)\n",
    "        self.max_tweets = max_tweets\n",
    "        self.batch_size = batch_size\n",
    "        #empty tweet representation\n",
    "        bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "        self.empty_tweet =  bert_model(**tokenizer('', return_tensors='tf'))['pooler_output'].numpy()\n",
    "        del bert_model\n",
    "        del tokenizer\n",
    "        self.date_limit = date_limit\n",
    "        self.gridfs = gridfs.GridFS(db, collection='fsProcessedTweets')\n",
    "        self._init_tweet_cache()\n",
    "        pass\n",
    "        \n",
    "    def _init_tweet_cache(self):\n",
    "        if not os.path.exists('training_tweets.npy'):\n",
    "            self.tweets = np.zeros((len(self.id_users), self.max_tweets, 768), dtype=np.float32)\n",
    "            for i, t in tqdm(enumerate(self.id_users), total=len(self.id_users)):\n",
    "                self.tweets[i, ...] = self._get_tweets_bert_base(t)\n",
    "            np.save('training_tweets.npy', self.tweets)\n",
    "            return\n",
    "        self.tweets = np.load('training_tweets.npy')\n",
    "        self.tweets = np.mean(self.tweets, axis=1)\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.idx_random) / self.batch_size)\n",
    "    \n",
    "    def _get_graph_for_node(self, node):\n",
    "        user = node#self.user_id[node]\n",
    "        node_map = {user: 0}\n",
    "        #Maps all the 1-level node to create the matrix\n",
    "        for neighbor in self.graph_replies.neighbors(node):\n",
    "            if neighbor not in node_map:\n",
    "                node_map[neighbor] = len(node_map)\n",
    "        for neighbor in self.graph_mentions.neighbors(node):\n",
    "            if neighbor not in node_map:\n",
    "                node_map[neighbor] = len(node_map)\n",
    "        for neighbor in self.graph_retweets.neighbors(node):\n",
    "            if neighbor not in node_map:\n",
    "                node_map[neighbor] = len(node_map)\n",
    "        #Creates the 3 matrixes\n",
    "        replies = np.eye(len(node_map))\n",
    "        mentions = np.eye(len(node_map))\n",
    "        retweets = np.eye(len(node_map))\n",
    "        #creates the Ã‚ matrix for the key node \n",
    "        for node, node_id in node_map.items():\n",
    "            for neighbor in self.graph_replies.neighbors(node):\n",
    "                if neighbor in node_map:\n",
    "                    replies[node_id, node_map[neighbor]] = 1\n",
    "                    \n",
    "            for neighbor in self.graph_mentions.neighbors(node):\n",
    "                if neighbor in node_map:\n",
    "                    mentions[node_id, node_map[neighbor]] = 1\n",
    "                    \n",
    "            for neighbor in self.graph_retweets.neighbors(node):\n",
    "                if neighbor in node_map:\n",
    "                    retweets[node_id, node_map[neighbor]] = 1\n",
    "        replies = normalized_adjacency(replies)\n",
    "        mentions = normalized_adjacency(mentions)\n",
    "        retweets = normalized_adjacency(retweets)\n",
    "        #Create the embedding vector\n",
    "        embeddings = np.zeros((len(node_map)))\n",
    "        for k, v in node_map.items():\n",
    "            #Convert the tweeter user id to the id acording to the nn\n",
    "            embeddings[v] = self.users_id[k] \n",
    "        return embeddings, replies, mentions, retweets\n",
    "\n",
    "    def _get_tweets_bert(self, node):\n",
    "        return self.tweets[int(node), ...]\n",
    "    \n",
    "    def _get_tweets_bert_base(self, node):\n",
    "        user_id = node##\n",
    "        query = {'userId': int(user_id)}\n",
    "        if self.date_limit is not None:\n",
    "            query['created'] = {'$lte': self.date_limit}\n",
    "        cursor = (\n",
    "            self.gridfs.\n",
    "            find(query).\n",
    "            sort([('created', pymongo.DESCENDING)]).\n",
    "            limit(self.max_tweets)\n",
    "        )\n",
    "        result = np.empty((self.max_tweets, 768))\n",
    "        i = 0\n",
    "        for file in cursor:\n",
    "            result[i, :] = np.load(file)['pooler_output']\n",
    "            i += 1\n",
    "        while i < self.max_tweets:\n",
    "            result[i, :] = self.empty_tweet\n",
    "            i += 1\n",
    "        return result\n",
    "    \n",
    "    def _get_instance(self, node):\n",
    "        embeddings, replies, mentions, retweets = self._get_graph_for_node(node)\n",
    "        bert_emb = np.empty((embeddings.shape[0], 768))\n",
    "        for i, node in enumerate(embeddings):\n",
    "            bert_emb[i, ...] = self._get_tweets_bert(node)\n",
    "        return embeddings, replies[:1, :], mentions[:1, :], retweets[:1, :], bert_emb\n",
    "    \n",
    "    def _to_batch(self, instances, max_users):\n",
    "        user_i = np.zeros((batch_size, max_users))\n",
    "        user_replies = np.zeros((batch_size, 1, max_users))\n",
    "        user_mentions = np.zeros((batch_size, 1, max_users))\n",
    "        user_retweet = np.zeros((batch_size, 1, max_users))\n",
    "        user_bert = np.zeros((batch_size, max_users, 768))\n",
    "        for i, (embeddings, replies, mentions, retweets, bert_emb) in enumerate(instances):\n",
    "            user_i[i, :embeddings.shape[0]] = embeddings\n",
    "            user_replies[i, :replies.shape[0], :replies.shape[1]] = replies\n",
    "            user_mentions[i, :mentions.shape[0], :mentions.shape[1]] = mentions\n",
    "            user_retweet[i, :retweets.shape[0], :retweets.shape[1]] = retweets\n",
    "            user_bert[i, :bert_emb.shape[0], ...] = bert_emb\n",
    "        return [user_i, user_replies, user_mentions, user_retweet, user_bert]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ids = self.idx_random[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        user_instances = [self._get_instance(self.user_pairs[idx][0]) for idx in ids]\n",
    "        target_instances = [self._get_instance(self.user_pairs[idx][1]) for idx in ids]\n",
    "        max_user = max([len(instance[0]) for instance in user_instances]) \n",
    "        max_target = max([len(instance[0]) for instance in target_instances])\n",
    "        current_batch_size = len(ids)\n",
    "        y = np.empty((current_batch_size, 2))\n",
    "        y[:, 0] = self.y_true[ids]\n",
    "        y[:, 1] = self.y_dist[ids]\n",
    "        return self._to_batch(user_instances, max_user) + self._to_batch(target_instances, max_target), y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.idx_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweets = 15\n",
    "batch_size = 20\n",
    "with open('train_ds_no_neg_smp.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "user_id = dataset.users_id\n",
    "\n",
    "dataset.batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.        ,  0.30577421],\n",
       "       [20.        ,  0.15665954],\n",
       "       [ 3.        ,  0.20631999],\n",
       "       [ 1.        ,  0.4004091 ],\n",
       "       [ 9.        ,  0.21486109],\n",
       "       [ 7.        ,  0.30761921],\n",
       "       [ 2.        ,  0.3770116 ],\n",
       "       [ 4.        ,  0.14760381],\n",
       "       [ 2.        ,  0.36941862],\n",
       "       [ 1.        ,  0.49283403],\n",
       "       [ 4.        ,  0.72401953],\n",
       "       [ 1.        ,  0.53957748],\n",
       "       [27.        ,  0.3639853 ],\n",
       "       [ 2.        ,  0.25687248],\n",
       "       [10.        ,  0.4633047 ],\n",
       "       [ 6.        ,  0.55535591],\n",
       "       [ 1.        ,  0.31043869],\n",
       "       [ 1.        ,  0.22685075],\n",
       "       [ 7.        ,  0.44471365],\n",
       "       [ 3.        ,  0.49664688]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Input, Embedding, Concatenate, \\\n",
    "                TimeDistributed, Lambda, Dot, Attention, GlobalMaxPool1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from spektral.layers.convolutional import GCNConv\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    #recibe indices con forma 1xvaloresx3 (indices + valor)\n",
    "    #trasnforma los indices a valoresx2 y los valores valoresx1\n",
    "    v_true, dist = y_true[:, 0], y_true[:, 1]\n",
    "    return K.mean(dist * K.square(y_pred - K.log(2 * v_true) / K.log(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_list (InputLayer)          [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_tweets_bert (InputLayer)   [(None, None, 768)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target_list (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target_tweets_bert (InputLayer) [(None, None, 768)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embeddings (Embedding)     (None, None, 64)     412800      user_list[0][0]                  \n",
      "                                                                 target_list[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "user_bert_dense (Dense)         (None, None, 64)     49216       user_tweets_bert[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "target_bert_dense (Dense)       (None, None, 64)     49216       target_tweets_bert[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "user_emb_plus_bert (Concatenate (None, None, 128)    0           user_embeddings[0][0]            \n",
      "                                                                 user_bert_dense[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "replies_user (InputLayer)       [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mentions_user (InputLayer)      [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retweets_user (InputLayer)      [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target_emb_plus_bert (Concatena (None, None, 128)    0           user_embeddings[1][0]            \n",
      "                                                                 target_bert_dense[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "replies_target (InputLayer)     [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mentions_target (InputLayer)    [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retweets_target (InputLayer)    [(None, None, None)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_replies_0 (GCNConv)         (None, None, 32)     4128        user_emb_plus_bert[0][0]         \n",
      "                                                                 replies_user[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gcn_mentions_0 (GCNConv)        (None, None, 32)     4128        user_emb_plus_bert[0][0]         \n",
      "                                                                 mentions_user[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gcn_retweets_0 (GCNConv)        (None, None, 32)     4128        user_emb_plus_bert[0][0]         \n",
      "                                                                 retweets_user[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gcn_t_replies_0 (GCNConv)       (None, None, 32)     4128        target_emb_plus_bert[0][0]       \n",
      "                                                                 replies_target[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gcn_t_mentions_0 (GCNConv)      (None, None, 32)     4128        target_emb_plus_bert[0][0]       \n",
      "                                                                 mentions_target[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gcn_t_retweets_0 (GCNConv)      (None, None, 32)     4128        target_emb_plus_bert[0][0]       \n",
      "                                                                 retweets_target[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "user_gnc (Concatenate)          (None, None, 96)     0           gcn_replies_0[0][0]              \n",
      "                                                                 gcn_mentions_0[0][0]             \n",
      "                                                                 gcn_retweets_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "target_gnc (Concatenate)        (None, None, 96)     0           gcn_t_replies_0[0][0]            \n",
      "                                                                 gcn_t_mentions_0[0][0]           \n",
      "                                                                 gcn_t_retweets_0[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "user_row (Lambda)               (None, 96)           0           user_gnc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "target_row (Lambda)             (None, 96)           0           target_gnc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "graph_reps_concat (Concatenate) (None, 192)          0           user_row[0][0]                   \n",
      "                                                                 target_row[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           6176        graph_reps_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 542,209\n",
      "Trainable params: 542,209\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_size = 64\n",
    "kernels = 32\n",
    "deep = 1\n",
    "\n",
    "embedded = Embedding(len(user_id), emb_size, name='user_embeddings')\n",
    "\n",
    "user_i = Input(shape=(None,), name='user_list', dtype=tf.int32)\n",
    "emb_user = embedded(user_i)\n",
    "\n",
    "target_i = Input(shape=(None,), name='target_list', dtype=tf.int32)\n",
    "emb_target = embedded(target_i)\n",
    "\n",
    "replies_user_i = Input(shape=(None, None), name='replies_user', dtype=tf.float32)\n",
    "mentions_user_i = Input(shape=(None, None), name='mentions_user', dtype=tf.float32)\n",
    "retweets_user_i = Input(shape=(None, None), name='retweets_user', dtype=tf.float32)\n",
    "\n",
    "replies_target_i = Input(shape=(None, None), name='replies_target', dtype=tf.float32)\n",
    "mentions_target_i = Input(shape=(None, None), name='mentions_target', dtype=tf.float32)\n",
    "retweets_target_i = Input(shape=(None, None), name='retweets_target', dtype=tf.float32)\n",
    "\n",
    "user_tweets_bert = Input(shape=(None, 768), name='user_tweets_bert')\n",
    "target_tweets_bert = Input(shape=(None, 768), name='target_tweets_bert')\n",
    "\n",
    "user_bert = Dense(emb_size, name='user_bert_dense')(user_tweets_bert)\n",
    "target_bert = Dense(emb_size, name='target_bert_dense')(target_tweets_bert)\n",
    "\n",
    "user_emb = Concatenate(name='user_emb_plus_bert', axis=-1)([emb_user, user_bert])\n",
    "target_emb = Concatenate(name='target_emb_plus_bert', axis=-1)([emb_target, target_bert])\n",
    "\n",
    "emb_rep, emb_men, emb_rt = user_emb, user_emb, user_emb\n",
    "emb_t_rep, emb_t_men, emb_t_rt = target_emb, target_emb, target_emb\n",
    "for i in range(deep):\n",
    "    emb_rep = GCNConv(kernels, name='gcn_replies_{}'.format(i))([emb_rep, replies_user_i])\n",
    "    emb_men = GCNConv(kernels, name='gcn_mentions_{}'.format(i))([emb_men, mentions_user_i])\n",
    "    emb_rt = GCNConv(kernels, name='gcn_retweets_{}'.format(i))([emb_rt, retweets_user_i])\n",
    "    \n",
    "    emb_t_rep = GCNConv(kernels, name='gcn_t_replies_{}'.format(i))([emb_t_rep, replies_target_i])\n",
    "    emb_t_men = GCNConv(kernels, name='gcn_t_mentions_{}'.format(i))([emb_t_men, mentions_target_i])\n",
    "    emb_t_rt = GCNConv(kernels, name='gcn_t_retweets_{}'.format(i))([emb_t_rt, retweets_target_i])\n",
    "    \n",
    "mat = Concatenate(name='user_gnc')([emb_rep, emb_men, emb_rt])\n",
    "mat = Lambda(lambda x: x[:, 0, :], name='user_row')(mat)\n",
    "\n",
    "mat_t = Concatenate(name='target_gnc')([emb_t_rep, emb_t_men, emb_t_rt])\n",
    "mat_t = Lambda(lambda x: x[:, 0, :], name='target_row')(mat_t)\n",
    "\n",
    "\n",
    "mat = Concatenate(name='graph_reps_concat')([mat, mat_t])\n",
    "mat = Dense(kernels)(mat)#, [0, 2, 1]\n",
    "mat = Dense(1)(mat)\n",
    "\n",
    "model = Model([user_i, replies_user_i, mentions_user_i, retweets_user_i, user_tweets_bert,\n",
    "              target_i, replies_target_i, mentions_target_i, retweets_target_i,target_tweets_bert], mat)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "15581/15581 [==============================] - 2818s 181ms/step - loss: 0.9392 - lr: 0.0010\n",
      "Epoch 2/4\n",
      "15581/15581 [==============================] - 2927s 188ms/step - loss: 0.8682 - lr: 0.0010\n",
      "Epoch 3/4\n",
      "15581/15581 [==============================] - 2717s 174ms/step - loss: 0.8631 - lr: 0.0010\n",
      "Epoch 4/4\n",
      "15581/15581 [==============================] - 2716s 174ms/step - loss: 0.8618 - lr: 9.0484e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f467817e730>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import os\n",
    "if not os.path.exists('connected-no-wide'):\n",
    "    os.makedirs('connected-no-wide')\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 2:\n",
    "        return lr\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "model.fit(dataset, epochs=4, callbacks=[ModelCheckpoint(filepath='connected-no-wide/{epoch:02d}-weights-neg-{loss:.5f}.hdf5',\n",
    "                                                        monitor='loss',\n",
    "                                                        save_best_only=False),\n",
    "                                         LearningRateScheduler(scheduler)], workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('connected-no-wide/model_rec-neg.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
